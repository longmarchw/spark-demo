//算法名称-K-means
import cn.neucloud.dasuan.SparkContextImpl
import cn.neucloud.dasuan.analysis.clustering.{BisectingKMeans, GaussianMixture, KMeans}
import cn.neucloud.dasuan.utils.DFTools
import org.apache.log4j.{Level, Logger}
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.sql.{DataFrame, Row, SQLContext}
val sqlContext = new SQLContext(sc)
//数据准备
val dataset: DataFrame = sqlContext.createDataFrame(Seq(
  (1, Vectors.dense(0.0, 0.0, 0.0)),
(2, Vectors.dense(0.1, 0.1, 0.1)),
(3, Vectors.dense(0.2, 0.2, 0.2)),
(4, Vectors.dense(9.0, 9.0, 9.0)),
(5, Vectors.dense(9.1, 9.1, 9.1)),
(6, Vectors.dense(9.2, 9.2, 9.2))
)).toDF("id", "features")
val k = 3
val numIterations = 20
val df = DFTools.df2DF4Kmeans(dataset, sc) 
val kmeans = new KMeans(df)
val clust = kmeans.clusterCenters(k, numIterations) 
println("Forecast category: " + kmeans.predict(Array(0, 0.0, 0.0, 1.0), clust))
println("Center point: " + kmeans.printCenters)
println("Contour factor: " + kmeans.silin.toString)
println("Euclidean distance:" + kmeans.ouj(clust)) 
