%livy.spark

//算法名称-层次聚类

import java.util
import cn.neucloud.dasuan.analysis.clustering.BisectingKMeans
import org.apache.spark.api.java.JavaSparkContext
import org.apache.spark.mllib.clustering.BisectingKMeansModel
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.sql.types.{DoubleType, StructField, StructType}
import org.apache.spark.sql.{Row, SQLContext}
import org.apache.spark.SparkConf

//spark上下文准备
val conf = new SparkConf().setAppName("BKMeansTest").setMaster("local[5]")
val jsc = JavaSparkContext.fromSparkContext(sc)
val sqlContext = new SQLContext(sc)
//数据准备
val data = jsc.parallelize(
 util.Arrays.asList(
  Row(1.0, 2.0),
  Row(2.0, 4.0),
  Row(3.0, 5.0),
  Row(4.5,5.0),
  Row(2.5,3.0)
   )
 )
val schemaString = "c1 c2"
val schema =StructType(schemaString.split(" ").map(fieldName => StructField(fieldName, DoubleType, true)))
val df = sqlContext.createDataFrame(data, schema)
//应用算法
val bkMeans = new BisectingKMeans
val model = bkMeans.cluster(sc,df, 3, 10, 2)
val df1 = bkMeans.getDataWithCluster()
df1.show()
//计算误差
val cost  = bkMeans.computeCost(model, df)
println(cost)
//新点预测
val point: Array[Double] = new Array[Double](2)
point(0) = 1
point(1) = 3
val pPoint = Vectors.dense(point)
val cluster = bkMeans.predict(model, pPoint)
println(cluster)

