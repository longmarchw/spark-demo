//算法名称-Sessionize
import cn.neucloud.dasuan.analysis.timeseries.Sessionize
import org.apache.spark.sql.SQLContext
import org.apache.spark.sql.types.{StringType, StructField, StructType}
import org.apache.spark.sql.{Row, SQLContext}
//import cn.neucloud.viz.cn.neucloud.viz.analysis.Visualize
//环境准备
val sqlContext = new SQLContext(sc)
//数据准备
val data = sc.parallelize(
   Seq(
     Row("01","20.12","2016-08-01 01:00:01.00"),
     Row("02","21.23","2016-08-01 01:00:02.00"),
     Row("03","24.45","2016-08-01 01:00:06.00"),
     Row("04","27.05","2016-08-01 01:00:07.00"),
     Row("05","27.10","2016-08-01 01:00:09.00"),
     Row("06","23.18","2016-08-01 01:00:11.00"),
     Row("07","29.10","2016-08-01 01:00:12.00")
     ),1
 )
val schemaString = "id tempreature timestamp"
val schema =StructType(schemaString.split(" ").map(fieldName => StructField(fieldName, StringType, true)))
val df = sqlContext.createDataFrame(data, schema)
//数据备注名sessionize-0.2
var s = new Sessionize
//应用算法
var df1 = s.byInterval(df, 3000L, "timestamp", 20)
df1.show
